{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корпус\n",
    "#### его содержимое, формат хранения + тегсет\n",
    "\n",
    "Корпус хранится в csv-файле, поскольку так было удобнее размечать данные. Ниже функция, переводящая в формат списка \"слово+часть речи\", более удобный для сравнения\n",
    "\n",
    "Также есть json-файл с делением на предложения, а не на токены, чтобы прогонять через модели, учитывающие контекст\n",
    "\n",
    "В корпус входят различные предложения, в основном, из новостей. Представлены различные части речи, омонимия, разрешаемая контекстом, сокращения, аббревиатуры, слова, отсутствующие в словарях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(tokens):\n",
    "    with open('corpus.csv', 'r', encoding='utf-8') as csvfile:\n",
    "        datareader = csv.reader(csvfile)\n",
    "        next(datareader)\n",
    "        for row in datareader:\n",
    "            tokens.append((row[0], row[1]))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "csv_to_list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.json', encoding=\"utf-8\") as file:\n",
    "    corpus = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 - количество токенов\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens), '- количество токенов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_tags = ['noun','adj','verb','adv','pron','comp','num','prep','conj','prcl','intj','apro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему именно такой набор частей речи?\n",
    "\n",
    "- причастия и деепричастия включены в глагол, так как если теггер помечает причастие как глагол, то нет смысла проверять, понимает ли он, что за форма глагола, ведь причастия имеют окончания, очень отличные от обычных глагольных финитных. Гораздо важнее проверить, что теггер отличает причастие от прилагательного, что данное обобщение не мешает делать\n",
    "- краткая и полная форма прилагательных в одном теге: по аналогичным причинам, хочется проверить скорее различение кратких прилагательных и существительных\n",
    "- местоимения pron и apro (местоимения-существительные и местоимения-прилагательные): с остальными классами местоимений обозначения у разных моделей очень разнятся. При этом так как местоимения - это закрытый класс со множеством супплетивных форм, их разбор легко сделать даже просто словарём, поэтому, вероятно, качественные теггеры уже сделали такой разбор, который считают правильным, и проверять это нет особого смысла\n",
    "- порядковые числительные помечаются как прилагательные, поскольку Natasha никак не различает их\n",
    "- компаратив объединяет сравнительные формы прилагательных и наречий, так как разбор таких случаев бывает спорным даже для человеческой разметки, а также Pymorphy не разделяет их"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pm = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, приводящая тег к нужному формату:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_dict = {'ADJF': 'adj',\n",
    "           'ADJS': 'adj',\n",
    "           'INFN': 'verb',\n",
    "           'PRTF': 'verb',\n",
    "           'PRTS': 'verb',\n",
    "           'GRND': 'verb',\n",
    "           'NUMR': 'num',\n",
    "           'ADVB': 'adv',\n",
    "           'NPRO': 'pron',\n",
    "          }\n",
    "\n",
    "def pm_tags(gr):\n",
    "    if 'Apro' in str(gr):\n",
    "        return 'apro'\n",
    "    tag = gr.POS\n",
    "    if tag == None:\n",
    "        return 'unkn'\n",
    "    if tag.lower() in our_tags:\n",
    "        return tag.lower()\n",
    "    elif tag in pm_dict:\n",
    "        new_tag = pm_dict[tag]        \n",
    "        return new_tag\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контекст не учитывается, поэтому смотрим по одному слову (и сразу сравниваем):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка, оригинал: ('НИУ', 'noun') , варианты: ['unkn']\n",
      "ошибка, оригинал: ('ВШЭ', 'noun') , варианты: ['unkn']\n",
      "ошибка, оригинал: ('один', 'num') , варианты: ['apro', 'apro']\n",
      "\n",
      "\n",
      " 0.9850746268656716 - accuracy Pymorphy\n"
     ]
    }
   ],
   "source": [
    "pm_c = 0\n",
    "for token in tokens:\n",
    "    a = pm.parse(token[0])\n",
    "    word_tags = []\n",
    "    for analyze in a:\n",
    "        w_tag = pm_tags(analyze.tag)\n",
    "        word_tags.append(str(w_tag))\n",
    "    if token[1] in word_tags:\n",
    "        pm_c += 1\n",
    "    else:\n",
    "        print('ошибка, оригинал:', token, ', варианты:', word_tags)\n",
    "\n",
    "print('\\n\\n', pm_c/len(tokens),'- accuracy Pymorphy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymystem3 import Mystem\n",
    "os.environ[\"MYSTEM_BIN\"] = \"C:\\\\mystem.exe\"\n",
    "ms = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_dict = {'A': 'adj',\n",
    "           'ADVPRO': 'adv',\n",
    "           'ANUM': 'adj',\n",
    "           'PART': 'prcl',\n",
    "           'PR': 'prep',\n",
    "           'S': 'noun',\n",
    "           'SPRO': 'pron',\n",
    "           'V': 'verb'\n",
    "          }\n",
    "\n",
    "\n",
    "def ms_tags(gr):\n",
    "    if 'срав' in gr:\n",
    "        return 'comp'\n",
    "    \n",
    "    tag = re.search(r'\\w+', gr).group(0)\n",
    "    \n",
    "    if tag.lower() in our_tags:\n",
    "        return tag.lower()\n",
    "    \n",
    "    elif tag in ms_dict:\n",
    "        new_tag = ms_dict[tag]\n",
    "        return new_tag\n",
    "    \n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 48980.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 41022.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 28613.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 73/73 [00:00<00:00, 72987.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 49944.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 28775.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "ms_tokens = []\n",
    "for sent in corpus:\n",
    "    ms_an = ms.analyze(sent[0])\n",
    "    sent_tokens = []\n",
    "    for token in tqdm(ms_an):\n",
    "        if 'analysis' in token:\n",
    "            word = token['text']\n",
    "            if len(token['analysis']) == 0:\n",
    "                sent_tokens.append((word, 'unkn'))\n",
    "            else:\n",
    "                features = token['analysis'][0]['gr']\n",
    "                tag = ms_tags(features)\n",
    "                sent_tokens.append((word, tag))\n",
    "    if len(sent_tokens) != sent[1]:\n",
    "        #проверяем, нет ли предложений, в которых токенизация прошла не так, как вручную (по количеству токенов в предложении)\n",
    "        print(sent, sent_tokens)\n",
    "    else:\n",
    "        ms_tokens.extend(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 - количество токенов\n"
     ]
    }
   ],
   "source": [
    "print(len(ms_tokens), '- количество токенов') #проверка общего количества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним с эталоном:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка: ('проверенным', 'verb') ('проверенным', 'adj')\n",
      "ошибка: ('ВШЭ', 'noun') ('ВШЭ', 'unkn')\n",
      "ошибка: ('ели', 'noun') ('ели', 'verb')\n",
      "ошибка: ('несколько', 'num') ('несколько', 'adv')\n",
      "ошибка: ('один', 'num') ('один', 'apro')\n",
      "ошибка: ('все', 'prcl') ('все', 'pron')\n",
      "ошибка: ('о', 'intj') ('о', 'prep')\n",
      "ошибка: ('старче', 'noun') ('старче', 'comp')\n",
      "ошибка: ('ли', 'prcl') ('ли', 'conj')\n",
      "ошибка: ('зорко', 'adj') ('зорко', 'adv')\n"
     ]
    }
   ],
   "source": [
    "ms_c = 0\n",
    "for i in range(len(tokens)):\n",
    "    if tokens[i][1] == ms_tokens[i][1]:\n",
    "        ms_c += 1\n",
    "    else:\n",
    "        print('ошибка:',tokens[i], ms_tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9502487562189055 - accuracy Mystem\n"
     ]
    }
   ],
   "source": [
    "print(ms_c/len(tokens), '- accuracy Mystem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(sent for (sent,num) in corpus)\n",
    "doc = Doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_dict = {'ADP': 'prep',\n",
    "            'PROPN': 'noun',\n",
    "            'AUX': 'verb',\n",
    "            'DET': 'apro',\n",
    "            'PART': 'prcl',\n",
    "            'SCONJ': 'conj',\n",
    "            'CCONJ': 'conj',\n",
    "            'PUNCT': 'punct'\n",
    "           }\n",
    "\n",
    "\n",
    "def nat_tags(token):\n",
    "    if 'Degree' in token.feats and token.feats['Degree'] == 'Cmp':\n",
    "        return 'comp'\n",
    "    \n",
    "    tag = token.pos\n",
    "    if tag.lower() in our_tags:\n",
    "        return tag.lower()\n",
    "    \n",
    "    elif tag in nat_dict:\n",
    "        new_tag = nat_dict[tag]        \n",
    "        return new_tag\n",
    "    \n",
    "    else:\n",
    "        print(tag)\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 19042.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 11003.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 15898.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 18938.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 51867.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 16908.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 14947.63it/s]\n"
     ]
    }
   ],
   "source": [
    "nat_tokens = []\n",
    "for sent in doc.sents:\n",
    "    a = sent.morph\n",
    "    for token in tqdm(a.tokens):\n",
    "        tag = nat_tags(token)\n",
    "        if tag not in ['punct']:\n",
    "            nat_tokens.append((token.text, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201  - количество токенов\n"
     ]
    }
   ],
   "source": [
    "print(len(nat_tokens), ' - количество токенов') # проверка совпадения токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка: ('что', 'conj') ('что', 'pron')\n",
      "ошибка: ('и', 'conj') ('и', 'prcl')\n",
      "ошибка: ('научусь', 'verb') ('научусь', 'noun')\n",
      "ошибка: ('тридцатое', 'adj') ('тридцатое', 'noun')\n",
      "ошибка: ('Качавшая', 'verb') ('Качавшая', 'adj')\n",
      "ошибка: ('его', 'apro') ('его', 'pron')\n",
      "ошибка: ('Ответь', 'verb') ('Ответь', 'noun')\n",
      "ошибка: ('о', 'intj') ('о', 'prep')\n",
      "ошибка: ('светла', 'adj') ('светла', 'noun')\n",
      "ошибка: ('зорко', 'adj') ('зорко', 'adv')\n"
     ]
    }
   ],
   "source": [
    "nat_c = 0\n",
    "for i in range(len(tokens)):\n",
    "    if tokens[i][1] == nat_tokens[i][1]:\n",
    "        nat_c += 1\n",
    "    else:\n",
    "        print('ошибка:', tokens[i], nat_tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9502487562189055 - accuracy Natasha\n",
      "0.9502487562189055 - accuracy Mystem\n",
      "0.9850746268656716 - accuracy Pymorphy\n"
     ]
    }
   ],
   "source": [
    "print(nat_c/len(tokens), '- accuracy Natasha')\n",
    "print(ms_c/len(tokens), '- accuracy Mystem')\n",
    "print(pm_c/len(tokens), '- accuracy Pymorphy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат: Pymorphy обогнал остальных, но только засчёт того, что предлагал несколько разборов. Так как для внедрения pos-теггера в предыдущую программу, нам нужно точно определять часть речи, Pymorphy будет работать значительно хуже, возьмём Natasha.\n",
    "\n",
    "(продолжение в тетрадке nlp_1_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
